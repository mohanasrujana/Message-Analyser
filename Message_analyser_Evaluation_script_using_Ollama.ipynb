{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 1. Set up Colab Environment\n",
        "#    - Open a Colab notebook.\n",
        "#    - Select a GPU runtime (Runtime > Change runtime type > T4 GPU).\n",
        "\n",
        "# 2. Install Dependencies\n",
        "#    - Install necessary libraries:\n",
        "#        !pip install ollama\n",
        "\n",
        "# 3. Install Ollama (within Colab)\n",
        "#    -  Ollama installation might throw warnings in Colab, installing these packages should resolve them\n",
        "#     !sudo apt update && sudo apt install pciutils lshw\n",
        "#    - Install Ollama:\n",
        "#        !curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# 4. Start Ollama Server (within Colab)\n",
        "#    - Start the Ollama server in the background:\n",
        "#        !nohup ollama serve > ollama.log 2>&1 &\n",
        "#    -  Wait for the server to initialize (about 10-20 seconds)."
      ],
      "metadata": {
        "id": "PX8P1gtVPJb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ollama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPYUczrYOxzM",
        "outputId": "5c6e7171-1cd4-495d-c010-74846c6c0fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ollama\n",
            "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: httpx<0.29,>=0.27 in /usr/local/lib/python3.11/dist-packages (from ollama) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from ollama) (2.11.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.33.1)\n",
            "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.13.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29,>=0.27->ollama) (1.3.1)\n",
            "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: ollama\n",
            "Successfully installed ollama-0.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt update && sudo apt install pciutils lshw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZusQVVxPHRi",
        "outputId": "3be97d29-fe1a-4493-d9e0-df96945c7cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [73.0 kB]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,693 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,101 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,837 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,161 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Fetched 24.9 MB in 5s (4,651 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "48 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "\u001b[1;33mW: \u001b[0mSkipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpci3 pci.ids usb.ids\n",
            "The following NEW packages will be installed:\n",
            "  libpci3 lshw pci.ids pciutils usb.ids\n",
            "0 upgraded, 5 newly installed, 0 to remove and 48 not upgraded.\n",
            "Need to get 883 kB of archives.\n",
            "After this operation, 3,256 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 pci.ids all 0.0~2022.01.22-1ubuntu0.1 [251 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libpci3 amd64 1:3.7.0-6 [28.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 lshw amd64 02.19.git.2021.06.19.996aaad9c7-2build1 [321 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 pciutils amd64 1:3.7.0-6 [63.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 usb.ids all 2022.04.02-1 [219 kB]\n",
            "Fetched 883 kB in 1s (1,246 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package pci.ids.\n",
            "(Reading database ... 126315 files and directories currently installed.)\n",
            "Preparing to unpack .../pci.ids_0.0~2022.01.22-1ubuntu0.1_all.deb ...\n",
            "Unpacking pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libpci3:amd64.\n",
            "Preparing to unpack .../libpci3_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking libpci3:amd64 (1:3.7.0-6) ...\n",
            "Selecting previously unselected package lshw.\n",
            "Preparing to unpack .../lshw_02.19.git.2021.06.19.996aaad9c7-2build1_amd64.deb ...\n",
            "Unpacking lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n",
            "Selecting previously unselected package pciutils.\n",
            "Preparing to unpack .../pciutils_1%3a3.7.0-6_amd64.deb ...\n",
            "Unpacking pciutils (1:3.7.0-6) ...\n",
            "Selecting previously unselected package usb.ids.\n",
            "Preparing to unpack .../usb.ids_2022.04.02-1_all.deb ...\n",
            "Unpacking usb.ids (2022.04.02-1) ...\n",
            "Setting up pci.ids (0.0~2022.01.22-1ubuntu0.1) ...\n",
            "Setting up lshw (02.19.git.2021.06.19.996aaad9c7-2build1) ...\n",
            "Setting up usb.ids (2022.04.02-1) ...\n",
            "Setting up libpci3:amd64 (1:3.7.0-6) ...\n",
            "Setting up pciutils (1:3.7.0-6) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XHJf8a2wPRk2",
        "outputId": "f4c67c6c-c61a-49c5-9e02-0b7d9017c5af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            ">>> NVIDIA GPU installed.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nohup ollama serve > ollama.log 2>&1 &"
      ],
      "metadata": {
        "id": "OLaGJypbPolF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ollama\n",
        "import re\n",
        "import subprocess\n",
        "import csv\n",
        "from typing import List, Tuple\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "XRdFrGKfOeyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_messages_with_model(conversation: str, ground_truth: str, model_name: str) -> Tuple[dict, list, list]:\n",
        "    \"\"\"\n",
        "    Args:\n",
        "        conversation:  A string containing the conversation to be analyzed.\n",
        "        ground_truth: A string containing the ground truth data.\n",
        "        model_name: The name of the language model being used.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing:\n",
        "        - A dictionary containing the evaluation metrics (precision, recall, F1)\n",
        "          for both Mens Rea and Actus Reus.\n",
        "        - A list of formatted Mens Rea messages.\n",
        "        - A list of formatted Actus Reus messages.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        mens_rea_prompt = f\"\"\"\n",
        "            You are an expert in criminal law and forensic analysis. Given a conversation related to a potential crime, your task is to extract messages based on the legal concept of \"mens rea\" (guilty mind).\n",
        "\n",
        "            **Definitions:**\n",
        "\n",
        "            * **Mens Rea (Guilty Mind):** This refers to the mental state of the perpetrator at the time the crime was committed. It encompasses the intention, knowledge, or recklessness that the person had when performing the act. In essence, it's about proving that the person knew what they were doing was wrong.\n",
        "\n",
        "            **Input:**\n",
        "\n",
        "            The input will be a conversation in the following format:\n",
        "\n",
        "            {conversation}\n",
        "\n",
        "            **Task:**\n",
        "\n",
        "            1.  Analyze each message in the provided conversation.\n",
        "            2.  Identify messages that indicate a guilty mind (mens rea) – messages that reveal intent, knowledge, or planning related to the crime.\n",
        "            3.  Output the results in the following format.  Do not include any introductory or explanatory text, only the list of messages:\n",
        "\n",
        "            Mens Rea:\n",
        "            [Message xx - Person]: <Message text>\n",
        "            [Message yy - Person]: <Message text>\n",
        "            ...etc\n",
        "            \"\"\"\n",
        "\n",
        "        actus_reus_prompt = f\"\"\"\n",
        "            You are an expert in criminal law and forensic analysis. Given a conversation related to a potential crime, your task is to extract messages based on the legal concept of \"actus reus\" (guilty act).\n",
        "\n",
        "            **Definitions:**\n",
        "\n",
        "            * **Actus Reus (Guilty Act):** This refers to the physical act of committing a crime. It's the tangible, observable action that constitutes the criminal offense.\n",
        "\n",
        "            **Input:**\n",
        "\n",
        "            The input will be a conversation in the following format:\n",
        "\n",
        "            {conversation}\n",
        "\n",
        "            **Task:**\n",
        "\n",
        "            1.  Analyze each message in the provided conversation.\n",
        "            2.  Identify messages that describe the guilty act itself (actus reus) – messages that detail the actions taken to commit the crime or cover it up.\n",
        "             3.  Output the results in the following format. Do not include any introductory or explanatory text, only the list of messages:\n",
        "\n",
        "            Actus Reus:\n",
        "            [Message xx - Person]: <Message text>\n",
        "            [Message yy - Person]: <Message text>\n",
        "            ...etc\n",
        "            \"\"\"\n",
        "        output_actus_reus = predict(model_name, actus_reus_prompt)\n",
        "        output_mens_rea = predict(model_name, mens_rea_prompt)\n",
        "\n",
        "\n",
        "        predicted_mens_rea = []\n",
        "        predicted_actus_reus = []\n",
        "\n",
        "\n",
        "        mens_rea_messages = re.findall(r\"\\[Message \\d+ - \\w+\\]: [^\\n]+\", output_mens_rea)\n",
        "        actus_reus_messages = re.findall(r\"\\[Message \\d+ - \\w+]: [^\\n]+\", output_actus_reus)\n",
        "        predicted_mens_rea = [msg.strip() for msg in mens_rea_messages]\n",
        "        predicted_actus_reus = [msg.strip() for msg in actus_reus_messages]\n",
        "\n",
        "\n",
        "        evaluation_results = evaluate_model_output(predicted_mens_rea, predicted_actus_reus, ground_truth)\n",
        "        return evaluation_results, predicted_mens_rea, predicted_actus_reus\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during analysis: {e}\")\n",
        "        return {}, [], []"
      ],
      "metadata": {
        "id": "7RDXyZyHQNAW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model_name: str, prompt: str) -> str:\n",
        "    \"\"\"\n",
        "    Generates a model prediction for a given prompt using Ollama.\n",
        "\n",
        "    Args:\n",
        "        model_name: The name of the model to use.\n",
        "        prompt: The prompt to send to the model.\n",
        "        num: The index of the current prediction.\n",
        "\n",
        "    Returns:\n",
        "        The generated text response from the model.\n",
        "    \"\"\"\n",
        "    response = ollama.chat(\n",
        "        model=model_name,\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "    )\n",
        "    return response[\"message\"][\"content\"]\n"
      ],
      "metadata": {
        "id": "wj1wVaj2QAHs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(dataset_path: str) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"\n",
        "    Loads the dataset from a CSV file.\n",
        "\n",
        "    Args:\n",
        "        dataset_path: The path to the CSV file.\n",
        "\n",
        "    Returns:\n",
        "        A tuple containing two lists:\n",
        "        - The first list contains the conversation prompts.\n",
        "        - The second list contains the ground truth data.\n",
        "    \"\"\"\n",
        "    prompts = []\n",
        "    ground_truths = []\n",
        "\n",
        "    print(f\"Loading dataset from {dataset_path}\")\n",
        "    with open(dataset_path, mode=\"r\", encoding=\"utf-8\") as csvfile:\n",
        "        reader = csv.DictReader(csvfile)\n",
        "        for row in reader:\n",
        "            prompts.append(row[\"conversation\"])\n",
        "            ground_truths.append(row[\"ground truth\"])\n",
        "    return prompts, ground_truths"
      ],
      "metadata": {
        "id": "JhwRmpPHP-C0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(model_name: str) -> None:\n",
        "    \"\"\"\n",
        "    Loads the specified language model using Ollama.\n",
        "\n",
        "    Args:\n",
        "        model_name: The name of the model to load (e.g., \"gemma3:12b\").\n",
        "    \"\"\"\n",
        "    print(f\"Pulling model: {model_name}\")\n",
        "    subprocess.run([\"ollama\", \"pull\", model_name], check=True)\n",
        "    print(f\"Model '{model_name}' pulled successfully.\")"
      ],
      "metadata": {
        "id": "7VwKxzUCP8He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_output(predicted_mens_rea: list, predicted_actus_reus: list, ground_truth: str) -> dict:\n",
        "    \"\"\"\n",
        "    Evaluates the model's output against the ground truth for both Mens Rea and Actus Reus.\n",
        "\n",
        "    Args:\n",
        "        predicted_mens_rea:  A list of messages predicted by the model for Mens Rea.\n",
        "        predicted_actus_reus: A list of messages predicted by the model for Actus Reus.\n",
        "        ground_truth: The ground truth string.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the precision, recall, and F1-score for both Mens Rea and Actus Reus.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ground_truth_data = preprocess_ground_truth(ground_truth)\n",
        "    mens_rea_metrics = calculate_precision_recall_f1(predicted_mens_rea, ground_truth_data[\"mens_rea\"])\n",
        "    actus_reus_metrics = calculate_precision_recall_f1(predicted_actus_reus, ground_truth_data[\"actus_reus\"])\n",
        "\n",
        "    return {\n",
        "        \"mens_rea\": mens_rea_metrics,\n",
        "        \"actus_reus\": actus_reus_metrics,\n",
        "    }"
      ],
      "metadata": {
        "id": "umfDe0QYP5Da"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculate_precision_recall_f1(predicted: list, ground_truth: list) -> dict:\n",
        "    \"\"\"\n",
        "    Calculates precision, recall, and F1-score.\n",
        "\n",
        "    Args:\n",
        "        predicted: A list of messages predicted by the model.\n",
        "        ground_truth: A list of messages from the ground truth.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing precision, recall, and F1-score.\n",
        "    \"\"\"\n",
        "    if not predicted and not ground_truth:\n",
        "        return {\"precision\": 1.0, \"recall\": 1.0, \"f1_score\": 1.0}\n",
        "\n",
        "    if not predicted:\n",
        "        return {\"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0}\n",
        "\n",
        "    if not ground_truth:\n",
        "        return {\"precision\": 0.0, \"recall\": 0.0, \"f1_score\": 0.0}\n",
        "\n",
        "    tp = sum(1 for p in predicted if p in ground_truth)\n",
        "    fp = len(predicted) - tp\n",
        "    fn = len(ground_truth) - tp\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
        "\n",
        "    return {\"precision\": precision, \"recall\": recall, \"f1_score\": f1_score}"
      ],
      "metadata": {
        "id": "_d1EZaYwP1BX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_ground_truth(ground_truth: str) -> dict:\n",
        "    \"\"\"\n",
        "    Preprocesses the ground truth string to extract Mens Rea and Actus Reus messages.\n",
        "\n",
        "    Args:\n",
        "        ground_truth: A string containing the ground truth data in the specified format.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary with keys \"mens_rea\" and \"actus_reus\", each containing a list of messages.\n",
        "        Returns empty lists if the sections are not found.\n",
        "    \"\"\"\n",
        "\n",
        "    mens_rea_messages = []\n",
        "    actus_reus_messages = []\n",
        "\n",
        "\n",
        "    mens_rea_match = re.search(r\"Mens Rea:\\n([\\s\\S]*?)(\\nActus Reus:|\\Z)\", ground_truth)\n",
        "    actus_reus_match = re.search(r\"Actus Reus:\\n([\\s\\S]*)\", ground_truth)\n",
        "\n",
        "    if mens_rea_match:\n",
        "        mens_rea_text = mens_rea_match.group(1).strip()\n",
        "        if mens_rea_text:\n",
        "            mens_rea_messages = re.findall(r\"\\[Message \\d+ - \\w+\\]: [^\\n]+\", mens_rea_text)\n",
        "\n",
        "    if actus_reus_match:\n",
        "        actus_reus_text = actus_reus_match.group(1).strip()\n",
        "        if actus_reus_text:\n",
        "            actus_reus_messages = re.findall(r\"\\[Message \\d+ - \\w+\\]: [^\\n]+\", actus_reus_text)\n",
        "\n",
        "\n",
        "    return {\"mens_rea\": mens_rea_messages, \"actus_reus\": actus_reus_messages}"
      ],
      "metadata": {
        "id": "fJ0amvwKPxoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the message analysis experiment.\n",
        "    \"\"\"\n",
        "    model_name = \"gemma3:12b\"\n",
        "    load_model(model_name)\n",
        "\n",
        "    dataset_path = \"/content/true_positives_conversations (2).csv\"\n",
        "    conversations, ground_truths = load_dataset(dataset_path)\n",
        "    print(\"Dataset loaded successfully.\")\n",
        "\n",
        "    overall_results = {\n",
        "        \"mens_rea\": {\"precision\": 0, \"recall\": 0, \"f1_score\": 0},\n",
        "        \"actus_reus\": {\"precision\": 0, \"recall\": 0, \"f1_score\": 0},\n",
        "    }\n",
        "    num_conversations = len(conversations)\n",
        "    output_csv_path = \"gemma3_predictions.csv\"\n",
        "    with open(output_csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csvfile:\n",
        "        fieldnames = [\n",
        "            \"conversation_index\",\n",
        "            \"conversation\",\n",
        "            \"ground_truth\",\n",
        "            \"mens_rea_prediction\",\n",
        "            \"actus_reus_prediction\",\n",
        "            \"mens_rea_precision\",\n",
        "            \"mens_rea_recall\",\n",
        "            \"mens_rea_f1\",\n",
        "            \"actus_reus_precision\",\n",
        "            \"actus_reus_recall\",\n",
        "            \"actus_reus_f1\",\n",
        "        ]\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "        writer.writeheader()\n",
        "\n",
        "        for i, (conversation, ground_truth) in enumerate(zip(conversations[195:],ground_truths[195:])):\n",
        "            print(f\"Analyzing conversation {num_conversations - len(conversations[195:])+i} of {num_conversations}:\")\n",
        "            results, mens_rea_output, actus_reus_output = analyze_messages_with_model(conversation, ground_truth, model_name)\n",
        "            print(f\"Evaluation results for conversation {i + 1}:\")\n",
        "            print(results)\n",
        "\n",
        "            writer.writerow(\n",
        "                {\n",
        "                    \"conversation_index\": num_conversations - len(conversations[195:])+i + 1,\n",
        "                    \"conversation\": conversation,\n",
        "                    \"ground_truth\": ground_truth,\n",
        "                    \"mens_rea_prediction\": mens_rea_output,\n",
        "                    \"actus_reus_prediction\": actus_reus_output,\n",
        "                    \"mens_rea_precision\": results[\"mens_rea\"][\"precision\"],\n",
        "                    \"mens_rea_recall\": results[\"mens_rea\"][\"recall\"],\n",
        "                    \"mens_rea_f1\": results[\"mens_rea\"][\"f1_score\"],\n",
        "                    \"actus_reus_precision\": results[\"actus_reus\"][\"precision\"],\n",
        "                    \"actus_reus_recall\": results[\"actus_reus\"][\"recall\"],\n",
        "                    \"actus_reus_f1\": results[\"actus_reus\"][\"f1_score\"],\n",
        "                }\n",
        "            )\n",
        "\n",
        "\n",
        "            overall_results[\"mens_rea\"][\"precision\"] += results[\"mens_rea\"][\"precision\"]\n",
        "            overall_results[\"mens_rea\"][\"recall\"] += results[\"mens_rea\"][\"recall\"]\n",
        "            overall_results[\"mens_rea\"][\"f1_score\"] += results[\"mens_rea\"][\"f1_score\"]\n",
        "\n",
        "            overall_results[\"actus_reus\"][\"precision\"] += results[\"actus_reus\"][\"precision\"]\n",
        "            overall_results[\"actus_reus\"][\"recall\"] += results[\"actus_reus\"][\"recall\"]\n",
        "            overall_results[\"actus_reus\"][\"f1_score\"] += results[\"actus_reus\"][\"f1_score\"]\n",
        "\n",
        "\n",
        "    for category in [\"mens_rea\", \"actus_reus\"]:\n",
        "        overall_results[category][\"precision\"] /= num_conversations\n",
        "        overall_results[category][\"recall\"] /= num_conversations\n",
        "        overall_results[category][\"f1_score\"] /= num_conversations\n",
        "\n",
        "    print(\"\\nOverall Evaluation Results:\")\n",
        "    print(overall_results)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqKpSd4WQQNz",
        "outputId": "b38ec641-d0ac-48d8-c80c-56c0b59bb904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pulling model: gemma3:12b\n",
            "Model 'gemma3:12b' pulled successfully.\n",
            "Loading dataset from /content/true_positives_conversations (2).csv\n",
            "Dataset loaded successfully.\n",
            "Analyzing conversation 195 of 200:\n",
            "Evaluation results for conversation 1:\n",
            "{'mens_rea': {'precision': 0.6111111111111112, 'recall': 0.9166666666666666, 'f1_score': 0.7333333333333334}, 'actus_reus': {'precision': 0.2857142857142857, 'recall': 0.2222222222222222, 'f1_score': 0.25}}\n",
            "Analyzing conversation 196 of 200:\n",
            "Evaluation results for conversation 2:\n",
            "{'mens_rea': {'precision': 0.1111111111111111, 'recall': 0.375, 'f1_score': 0.17142857142857143}, 'actus_reus': {'precision': 0.25, 'recall': 0.42857142857142855, 'f1_score': 0.3157894736842105}}\n",
            "Analyzing conversation 197 of 200:\n",
            "Evaluation results for conversation 3:\n",
            "{'mens_rea': {'precision': 0.5833333333333334, 'recall': 0.30434782608695654, 'f1_score': 0.4}, 'actus_reus': {'precision': 0.5714285714285714, 'recall': 0.8, 'f1_score': 0.6666666666666666}}\n",
            "Analyzing conversation 198 of 200:\n",
            "Evaluation results for conversation 4:\n",
            "{'mens_rea': {'precision': 0.16, 'recall': 0.8, 'f1_score': 0.26666666666666666}, 'actus_reus': {'precision': 0.0, 'recall': 0.0, 'f1_score': 0.0}}\n",
            "Analyzing conversation 199 of 200:\n",
            "Evaluation results for conversation 5:\n",
            "{'mens_rea': {'precision': 0.3333333333333333, 'recall': 0.8571428571428571, 'f1_score': 0.48}, 'actus_reus': {'precision': 0.8, 'recall': 0.8, 'f1_score': 0.8000000000000002}}\n",
            "\n",
            "Overall Evaluation Results:\n",
            "{'mens_rea': {'precision': 0.008994444444444446, 'recall': 0.0162657867494824, 'f1_score': 0.010257142857142859}, 'actus_reus': {'precision': 0.009535714285714286, 'recall': 0.011253968253968254, 'f1_score': 0.010162280701754386}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evalmetric_from_prestored_data(file_name):\n",
        "  import pandas as pd\n",
        "  f = pd.read_csv(file_name)\n",
        "  length_of_data = len(f)\n",
        "  precision_mens_rea = sum(f[\"mens_rea_precision\"].tolist())/len(f)\n",
        "  recall_mens_rea = sum(f[\"mens_rea_recall\"].tolist())/len(f)\n",
        "  f1_score_mens_rea = sum(f[\"mens_rea_f1\"].tolist())/len(f)\n",
        "  precision_actus_reus = sum(f[\"actus_reus_precision\"].tolist()) / len(f)\n",
        "  recall_actus_reus = sum(f[\"actus_reus_recall\"].tolist()) / len(f)\n",
        "  f1_score_actus_reus = sum(f[\"actus_reus_f1\"].tolist()) / len(f)\n",
        "  return {\"mens_rea\": {\"precision\": precision_mens_rea, \"recall\": recall_mens_rea, \"f1_score\": f1_score_mens_rea}, \"actus_reus\": {\"precision\": precision_actus_reus, \"recall\": recall_actus_reus, \"f1_score\": f1_score_actus_reus}}\n"
      ],
      "metadata": {
        "id": "c3vbuOqI2Rwg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = evalmetric_from_prestored_data(\"/content/evaluations_gemma3 - gemma3_predictions.csv\")"
      ],
      "metadata": {
        "id": "uiRGCrGB4Hp4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21b2a48e-d8b7-486c-942c-60f865ee0992"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in results:\n",
        "  print(\"Crime element: {}\\n Evaluation metrics:{}\".format(i, results[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EvmrCiPd4QPT",
        "outputId": "f5ff8c86-6170-40ce-f715-4b52e9dd1cc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Crime element: mens_rea\n",
            " Evaluation metrics:{'precision': 0.47789640839893954, 'recall': 0.588145181184343, 'f1_score': 0.5003866544429296}\n",
            "Crime element: actus_reus\n",
            " Evaluation metrics:{'precision': 0.3813628229732829, 'recall': 0.5300570097368688, 'f1_score': 0.41793140176060606}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}